The modules system
==================

The aim of the new modules system was to get away from the human-controlled connectivity
of modules and data by editing main.c manually every time, as well as reduce interdepen-
cies between modules, and the hassle of recompiling every time and hope you did it right.
The new system truly separates modules out into shared libraries, which define what kind
of inputs they can take and what kind of outputs they may generate. The main application
provides a platform to load/unload those modules, connect them according to dynamic con-
figuration using the usual hierarchical storage, and then run the modules as usual.
Doing it this way, with the system building up the connectivity map, also means that it's
now possible to query the system about such details; Where does the data I consume come
from? How many modules are using this data? and so forth, without actually having to wait
for the data to be produced and get there. So modules can now wait inside Init() for the
data producers they need to be running, and then get information on sizes or devices right
away, without having to (ab)use the Run() function for that.
The main points to follow when coding a new module are explained in 'README.porting', so
here we'll only touch on how some of those things influence module connectivity.
To start with, there now is only one main loop of execution, whose configuration is loaded
from the XML configuration file at startup, and that can be edited as usual via the config
server at run-time, using caer-ctl or GUI tools. This means all modules and their configu-
ration now live directly in the root path /.

  <sshs version="1.0">
      <node name="" path="/">
          <node name="bafilter" path="/bafilter/">
              ....
          </node>
      </node>
  </sshs>

Each module is uniquely identified by a short name now, that the user can freely decide on.
There is only one reserved name: 'caer', which is used for system settings.
Each module, in addition to its own configuration parameters, always contains the following
two parameters:

  <attr key="moduleId" type="short">2</attr>
  <attr key="moduleLibrary" type="string">caer_bafilter</attr>

The 'moduleId' short integer is a unique ID that is used internally and in the configuration
to reference modules, inputs and outputs to each-other. The ID is automatically chosed when
adding/removing modules through the appropriate configuration interfaces, and should usually
not be edited by hand; though it is possible to do so: just remember an ID has to be unique,
and to update all the other references to it inside the configuration, if you do so.
The 'moduleLibrary' string is the name of the shared library that is to be loaded for that
module to run. At startup the given modules search path (which can be configured in
'/caer/modules/:moduleSearchPath') is recursively searched for any file with the right
extension for a shared library (.so on Linux, .dll on Windows, .dylib on MacOS X), and those
are added to a list of possible modules. When loading a module, the string in 'moduleLibrary'
is searched for inside this list, and if found, that file is then loaded and processed.
At load time, the module is queried for information on itself by calling its caerModuleGetInfo()
function, which returns a pointer to a 'caerModuleInfo' structure. This structure contains all
the required information to setup the module and then run it; it especially contains information
about what event streams the module can take as input, and what event streams it can generate
as output. An event stream is a sequence of event packets, coming from the same source and
with the same type. Let's take a look at the structure to better understand it:

  static const struct caer_module_info BAFilterInfo = {
      .version = 1,
      .name = "BAFilter",
      .type = CAER_MODULE_PROCESSOR,
      .memSize = sizeof(struct BAFilter_state),
      .functions = &BAFilterFunctions,
      .inputStreams = BAFilterInputs,
      .inputStreamsSize = CAER_EVENT_STREAM_IN_SIZE(BAFilterInputs),
      .outputStreams = NULL,
      .outputStreamsSize = 0
  };

The 'version' field simply contains an informative version of the module, and the 'name' field
contains the module's name. The 'type' field is important, as it indicates what kind of module
this is, and what operations it is allowed to do on data; there are three types:

- CAER_MODULE_INPUT: an input module, it generates data and puts it into the cAER processing
  system; such a module can only have output streams defined and no input streams.
- CAER_MODULE_OUTPUT: an output module, it takes data and gets it out of cAER, for example by
  visualizing it or writing it to a file. It can only have input streams, and no output streams.
- CAER_MODULE_PROCESSOR: a processor modules, it takes data in and transforms it or uses it to
  generate new data. Most modules that implement useful algorithms will be PROCESSORs.

The 'memSize' field indicates how much memory has to be allocated for the module's state, and
the 'functions' field specifies where to find the 'Init', 'Exit', 'Run', 'Config' and 'Reset'
functions that make up the meat of a module.

The next fields are critical to the new module system: the 'inputStreams' field specifies what
inputs this module accepts, it is an array of 'inputStreamSize' size, made up of structures of
type 'caer_event_stream_in':

  struct caer_event_stream_in {
      int16_t type; // Use -1 for any type.
      int16_t number; // Use -1 for any number of.
      bool readOnly; // True if input is never modified.
  };

'type' specifies the type that can be taken as input, 'number' tells how many of those, and
'readOnly' indicates whether their content is modified (readOnly=false) or not (readOnly=true).
For special cases, it is possible to specify -1 as type, which means any type can be taken as
input, this is useful for modules like Statistics. In this case, number may be either -1 or 1,
to take any number, or exactly 1, such input of any type. When the type=-1 notation is used,
that is the only element allowed in the array.
Else you can have one element per type in the array, ordered by ascending type ID, with number
set to either -1 (for any number of that type), or >0 (for exactly that many of that type).
It is currently not possible to apply 'readOnly' with finer granularity, it will apply to all
inputs of a type, so even if you accept 3 inputs of type A, one of which you do not modify,
you still have to declare the whole group readOnly=false, as you do modify the other two.
Only OUTPUT and PROCESSOR type modules can have inputs specified, in fact they all must have
at least one input element present. All OUTPUT type modules must also declare all their inputs
to be readOnly=true, because moving the data somewhere else or showing it should never change it.

The 'outputStreams' and 'outputStreamsSize' of the main module info structure work analogously,
they define an array of 'caer_event_stream_out' elements that define which new data a module
generates. Only INPUT and PROCESSOR modules can have outputs, where INPUT modules must have at
least one, while PROCESSOR modules can have no new data outputs IFF they have at least one
input that is not marked with readOnly=true, meaning they do modify that event stream at least.
The output elements are simpler than the input ones:

  struct caer_event_stream_out {
      int16_t type; // Use -1 for undefined output (determined at runtime from configuration).
  };

In fact they only have a type, since each module can only ever output exactly one event stream
per type. This follows from the fact that event packets only have their type ID and source ID
to differentiate them, since all the data being generated by a module must have the source ID
set to that module's ID, only the type ID remains as a distinction, and there can only be
one per type, as with more, you'd have packets that can't be identified correctly.
Type can also be set to -1, in which case what types this module outputs are determined at
run-time from the configuration, this is useful for modules such as File or Network inputs,
where they can produce any type, but we don't have any information about which types will
actually be produced when setting up module connectivity (this is before any module configuration
or initialization takes place, so we have no idea what File or IP:Port to connect to to even
try and get that information), so this choice is left to the user. In this case, this is the
only element of the output streams array, and the configuration parameter of type string with
name 'moduleOutput' will instead determine the types. That parameter will have the type IDs
separated by a comma, like this (duplicates are not allowed):

  <attr key="moduleOutput" type="string">0,1,3</attr>

Every (source ID, type ID) output combination is an event stream, which can then be used
as input by other modules, to read or modify data (provided the types agree).

Now that you've seen that for undefined type outputs (type=-1) a configuration parameter
determines the actual values, you may be wondering if the same is true for the input side
of things when type is set to -1 (any) there; in fact all modules that accept input must
always have a string configuration parameter called 'moduleInput'. This specifies all the
inputs that are actually connected to a module at run-time, whereas the above 'inputStreams'
array just indicates the possibilities that this run-time configuration will then be checked
against. The 'moduleInput' parameter will look like this:

  <attr key="moduleInput" type="string">1[0,1a2] 2[2,3a4]</attr>

Each token is made up of a source module ID, the number outside the brackets, and inside you'll
find a comma-separated list of type IDs to take from that source ID. Each (source ID, type ID)
combination defines an event stream to connect as input, so in the above example:
(Source: 1, Type: 0), (Source: 1, Type: 1), (Source: 2, Type: 2) and (Source: 2, Type: 3).
You'll notice that some type IDs have the character 'a' followed by a number in them, this is
the mechanism used to encode dependencies: multiple modules may use an event stream, and some
of them (PROCESSOR type modules) may modify the event stream's content, changing events or
invalidating them. Modules thus need a mechanism to specify at which point they want to tap
the event stream to get their input; the 'a' here stands for 'afterModuleID', so the number
after the character 'a' encodes which module must run before that event stream is used by this
one. No 'a' character means the original event stream, as it comes out of the source, is to
be used. So the above example conveys the following information about the inputs of a module:
- use event stream from Source 1, Type 0, as it comes out originally
- use event stream from Source 1, Type 1, after the module with ID 2 has processed it
- use event stream from Source 2, Type 2, as it comes out originally
- use event stream from Source 2, Type 3, after the module with ID 4 has processed it
Each source ID token can only appear once, and the types inside one bracket pair also can only
appear once. Tokens are separated by a white-space character.

With the above information, you should now be able to understand the example XML configuration
file found in 'docs/davis-config.xml' fully, and possibly edit to include other modules or
change the connectivity, though it is heavily preferred to do so using the graphical tools.

All the modules related configuration is elaborated when the main execution loop starts, so it
is possible to change it while the system is running, and then simply stop and start the main
loop to load the new configuration. The configuration is heavily checked against all possible
manners of errors, such as duplicate IDs, missing libraries, or dependency cycles in event
streams. Once everything has been checked, a dependency graph is built and a final order of
execution for the modules is generated that respects all dependencies and tries to minimize
the times data needs to be copied around (which happens when two different modules declare
they need the same input and both modify it).
